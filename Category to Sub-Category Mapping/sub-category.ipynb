{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python36764bit18f7939e71684d01b5fb09541e8d6757",
      "display_name": "Python 3.6.7 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "05ece30799c2dcdac4c13b3af20453da19de8df0d9a1de52cff7e0b6e1e82bdd"
      }
    }
  },
  "cells": [
    {
      "source": [
        "# Requirements\n",
        "## Python Env\n",
        "- This Notebook requires at least Python 3.6.7\n",
        "## Required Python Modules\n",
        "Install these from a terminal using \"pip3 install module_name\"\n",
        "- pandas\n",
        "- numpy\n",
        "- tqdm\n",
        "- openpyxl (engine: does not need to be imported)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtAyuYITBErE"
      },
      "source": [
        "'''\n",
        "pandas will be our data manipulation module\n",
        "'''\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None, 'display.max_rows', 200)\n",
        "\n",
        "'''\n",
        "numpy will be our array computing module\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "'''\n",
        "tqdm allows us to easily add progress bars to our processes\n",
        "'''\n",
        "from tqdm import tqdm\n",
        "\n",
        "'''\n",
        "display will allow us to easily display custom data types like dataframes\n",
        "'''\n",
        "from IPython.display import display\n",
        "\n",
        "'''\n",
        "built-in python modules\n",
        "'''\n",
        "import os\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "source": [
        "# Category & Sub-Category Spreadsheet"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "subcat_df = pd.read_excel('cat-subcat.xlsx', engine='openpyxl') # requires openpyxl python module, use pip3 install openpyxl to install in your python3 env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Category             Sub-Category\n",
              "0         technology      technology_platform\n",
              "1         technology                 startups\n",
              "2         technology                  startup\n",
              "3    web_development                 services\n",
              "4    web_development                 software\n",
              "..               ...                      ...\n",
              "292         nanotech         microfabrication\n",
              "293         nanotech    molecular_engineering\n",
              "294         nanotech  molecular_self-assembly\n",
              "295         nanotech            nanomaterials\n",
              "296             pets                     pets\n",
              "\n",
              "[297 rows x 2 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Sub-Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>technology</td>\n      <td>technology_platform</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>technology</td>\n      <td>startups</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>technology</td>\n      <td>startup</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>web_development</td>\n      <td>services</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>web_development</td>\n      <td>software</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>nanotech</td>\n      <td>microfabrication</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>nanotech</td>\n      <td>molecular_engineering</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>nanotech</td>\n      <td>molecular_self-assembly</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>nanotech</td>\n      <td>nanomaterials</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>pets</td>\n      <td>pets</td>\n    </tr>\n  </tbody>\n</table>\n<p>297 rows × 2 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "subcat_df = subcat_df[subcat_df.Category.notna()]\n",
        "subcat_df = subcat_df.drop(columns='Unnamed: 0')\n",
        "subcat_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['application', 'service', 'provider']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "subcat_df.iloc[49]['Sub-Category'].split('_')"
      ]
    },
    {
      "source": [
        "The commands below were used to clean the original excel into the above."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(0, subcat_df.index.size):\n",
        "#     subcat_df['Sub-Category'] = subcat_df['Sub-Category'].replace(subcat_df.iloc[i]['Sub-Category'], '_'.join(subcat_df.iloc[i]['Sub-Category'].split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# subcat_df.to_excel('cat-subcat.xlsx', engine='openpyxl')"
      ]
    },
    {
      "source": [
        "## Converting Category/Sub-Category Dataframe into a Python Dictionary"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "categories = []\n",
        "sub_categories = []\n",
        "\n",
        "for i in range(0, subcat_df.index.size):\n",
        "    sub_categories.append(subcat_df.iloc[i]['Sub-Category'].replace(u'\\u200e', ''))\n",
        "\n",
        "    if subcat_df.iloc[i]['Category'] not in categories:\n",
        "        categories.append(subcat_df.iloc[i]['Category'])"
      ]
    },
    {
      "source": [
        "## Sub-Category Value Count Dictionary"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Value_Count:\n",
        "    '''\n",
        "    This class will keep and maintain and internal dictionary used\n",
        "    for calculating value counts of sub-categories.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.value_count = {}\n",
        "\n",
        "        for sc in sub_categories: # this initializes all the sub-categories\n",
        "                                  # with a value count of 0\n",
        "            self.value_count[sc] = 0\n",
        "    \n",
        "    def check_values(self, word, surrounding):\n",
        "        '''\n",
        "        this method takes a word, along with the next 4 words following it, as its \n",
        "        parameters and increments either the value count of word or the value count\n",
        "        of a term found in the surround words self.value_count depending on how many\n",
        "        times this word is found accross the several sub-categories. returns a boolean\n",
        "        value that indicates whether a match was found.\n",
        "        '''\n",
        "        global subcat_df\n",
        "        punc = '''!()[]{};:\"\\,<>./?@#$%^&*_~''' # this will be used to strip words and\n",
        "                                                # surrounding words of punctuation\n",
        "        match_found = False # this variable will be updated below and returned at the end\n",
        "        word = word.lower() # makes word lowercase\n",
        "        \n",
        "        surrounding = [x.lower() for x in surrounding] # makes all words lowercase\n",
        "        # the command below removes all punctuation in surrounding\n",
        "        surrounding = [x.translate(str.maketrans(\"\",\"\", punc)) for x in surrounding]\n",
        "        \n",
        "        # here we separate surrounding into 2-word, 3-word, and 4-word terms used\n",
        "        # to match sc's with more than one word\n",
        "        surr_2 = ' '.join(surrounding[:2])\n",
        "        surr_3 = ' '.join(surrounding[:3])\n",
        "        surr_4 = ' '.join(surrounding[:4])\n",
        "\n",
        "        for sc in sub_categories:\n",
        "            if len(sc.split('_')) > 1: # if there is > 1 word in sc\n",
        "\n",
        "                if surr_2 == ' '.join(sc.split('_')) or surr_3 == ' '.join(sc.split('_')) or surr_4 == ' '.join(sc.split('_')):\n",
        "                    # print('MATCH! ~~~ ' + surr_2)\n",
        "                    match_found = True\n",
        "\n",
        "                    self.value_count[sc] += 1\n",
        "                else:\n",
        "                    for i in sc.split('_'): # iterate through every word\n",
        "                        if i.lower() == word:\n",
        "                            # print('MATCH! ~~~ ' + word)\n",
        "                            match_found = True\n",
        "\n",
        "                            if word not in self.value_count.keys():\n",
        "                                if word != 'of' and word != 'and':\n",
        "                                    try:\n",
        "                                        self.value_count[word] = 1\n",
        "                                        subcat_df = subcat_df.append({'Category': cat_subcat(sc)[0], 'Sub-Category': word}, ignore_index=True, verify_integrity=True)\n",
        "                                    except ValueError: # Duplicate\n",
        "                                        continue\n",
        "                            else:\n",
        "                                self.value_count[word] += 1\n",
        "                        \n",
        "            else:\n",
        "                if sc.lower() == word:\n",
        "                    # print('MATCH! ~~~ ' + word)\n",
        "\n",
        "                    if word not in self.value_count.keys():\n",
        "                        self.value_count[word] = 1\n",
        "                    else:\n",
        "                        self.value_count[word] += 1\n",
        "\n",
        "                    self.value_count[sc] += 1\n",
        "\n",
        "        return match_found\n",
        "\n",
        "    def final_count(self):\n",
        "        '''\n",
        "        this method removes all entries in self.value_count that had a value count of 0\n",
        "        '''\n",
        "        self.value_count = {i: j for i,j in self.value_count.items() if j!=0}"
      ]
    },
    {
      "source": [
        "## Method That Maps a Sub-Category To Its Corresponding Category"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.07 ms, sys: 254 µs, total: 1.32 ms\nWall time: 2.46 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('clean-tech', 'green_transportation')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def cat_subcat(subcat):\n",
        "    try:\n",
        "        cat = subcat_df[subcat_df['Sub-Category'] == subcat]['Category'].index[0]\n",
        "        return (subcat_df.loc[cat, 'Category'], subcat)\n",
        "    except Exception:\n",
        "        return (None, None)\n",
        "\n",
        "%time cat_subcat('green_transportation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG5hIJvOCjSK"
      },
      "source": [
        "# COLUMNS AND INDICES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHphbEC-CH7t",
        "outputId": "ffc73e43-b109-4a3b-8f52-a77623221fda"
      },
      "source": [
        "column_dtypes = {'short_description': object, 'description': object, 'overview': object}\n",
        "\n",
        "dataframe = pd.read_csv(os.getcwd() + '/objects.csv', dtype=column_dtypes, low_memory=False)\n",
        "print(f'Columns:\\n\\t{dataframe.columns}\\n\\n')\n",
        "print(f'Indeces:\\n\\t{dataframe.index}\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns:\n\tIndex(['id', 'entity_type', 'entity_id', 'parent_id', 'name',\n       'normalized_name', 'permalink', 'category_code', 'status', 'founded_at',\n       'closed_at', 'domain', 'homepage_url', 'twitter_username', 'logo_url',\n       'logo_width', 'logo_height', 'short_description', 'description',\n       'overview', 'tag_list', 'country_code', 'state_code', 'city', 'region',\n       'first_investment_at', 'last_investment_at', 'investment_rounds',\n       'invested_companies', 'first_funding_at', 'last_funding_at',\n       'funding_rounds', 'funding_total_usd', 'first_milestone_at',\n       'last_milestone_at', 'milestones', 'relationships', 'created_by',\n       'created_at', 'updated_at'],\n      dtype='object')\n\n\nIndeces:\n\tRangeIndex(start=0, stop=462651, step=1)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "software            17922\n",
              "web                 15118\n",
              "other               13617\n",
              "ecommerce            9065\n",
              "games_video          7520\n",
              "mobile               6862\n",
              "advertising          6098\n",
              "consulting           5006\n",
              "enterprise           4441\n",
              "biotech              4430\n",
              "hardware             2951\n",
              "education            2901\n",
              "public_relations     2846\n",
              "network_hosting      2350\n",
              "search               2182\n",
              "cleantech            1940\n",
              "health               1698\n",
              "finance              1386\n",
              "social               1310\n",
              "security             1171\n",
              "medical              1153\n",
              "analytics            1022\n",
              "legal                1012\n",
              "travel                936\n",
              "local                 785\n",
              "news                  768\n",
              "hospitality           768\n",
              "semiconductor         696\n",
              "manufacturing         680\n",
              "sports                675\n",
              "music                 581\n",
              "fashion               563\n",
              "photo_video           544\n",
              "transportation        489\n",
              "real_estate           474\n",
              "messaging             296\n",
              "automotive            291\n",
              "design                281\n",
              "nonprofit             184\n",
              "nanotech               70\n",
              "pets                   61\n",
              "government             43\n",
              "Name: category_code, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataframe['category_code'].value_counts()"
      ]
    },
    {
      "source": [
        "# Cleaning Our Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Dropping Companies with entity_type != 'Company'"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266098 entries were dropped.\n"
          ]
        }
      ],
      "source": [
        "entries_before_drop = dataframe.index.size\n",
        "\n",
        "dataframe = dataframe[dataframe['entity_type'] == 'Company']\n",
        "\n",
        "print(str(entries_before_drop - dataframe.index.size) + ' entries were dropped.')"
      ]
    },
    {
      "source": [
        "## Dropping Companies With Disqualifying status"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# entries_before_drop = dataframe.index.size\n",
        "\n",
        "# dataframe = dataframe.drop(dataframe[dataframe['status'] == 'closed'].index)\n",
        "# dataframe = dataframe.drop(dataframe[dataframe['status'] == 'acquired'].index)\n",
        "\n",
        "# print(str(entries_before_drop - dataframe.index.size) + ' entries were dropped.')"
      ]
    },
    {
      "source": [
        "# Checking if All Entries Have at Least one of \\['overview', 'description', 'short_description', 'tag_list'\\]"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       short_description description overview tag_list  good2go\n",
              "27                   NaN         NaN      NaN      NaN    False\n",
              "29                   NaN         NaN      NaN      NaN    False\n",
              "42                   NaN         NaN      NaN      NaN    False\n",
              "70                   NaN         NaN      NaN      NaN    False\n",
              "73                   NaN         NaN      NaN      NaN    False\n",
              "...                  ...         ...      ...      ...      ...\n",
              "196533               NaN         NaN      NaN      NaN    False\n",
              "196534               NaN         NaN      NaN      NaN    False\n",
              "196535               NaN         NaN      NaN      NaN    False\n",
              "196536               NaN         NaN      NaN      NaN    False\n",
              "196546               NaN         NaN      NaN      NaN    False\n",
              "\n",
              "[64446 rows x 5 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>short_description</th>\n      <th>description</th>\n      <th>overview</th>\n      <th>tag_list</th>\n      <th>good2go</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>196533</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>196534</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>196535</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>196536</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>196546</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>64446 rows × 5 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "descriptors = ['short_description', 'description', 'overview', 'tag_list', 'good2go']\n",
        "\n",
        "dataframe['good2go'] = np.where(dataframe['short_description'].notna() | dataframe['description'].notna() | dataframe['overview'].notna() | dataframe['tag_list'].notna(), True, False)\n",
        "\n",
        "dataframe[dataframe['good2go'] == False][descriptors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31993406358590304"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "62884/dataframe.index.size"
      ]
    },
    {
      "source": [
        "As we can see, 62,884 rows have missing data in all three descriptor columns. This is almost 34.07% of all data, so we will need another algorithm to find the sub-category for the other data. For now, we will divide our dataset into two halves to solve individually."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "descriptive_df = dataframe[dataframe['good2go'] == True]\n",
        "nondes_df = dataframe[dataframe['good2go'] == False]"
      ]
    },
    {
      "source": [
        "# Merging Our Descriptive Columns Into One"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Merging Columns: 100%|██████████| 132107/132107 [03:29<00:00, 629.57entries/s]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    - This process is expected to take ~3:02 minutes.\n",
        "'''\n",
        "def merge_descriptives(df):\n",
        "    '''\n",
        "    This method will concatonate all descriptive columns in an entry\n",
        "    into a single column called 'info'.\n",
        "    '''\n",
        "    info = []\n",
        "\n",
        "    for i in tqdm(range(0, df.index.size), desc='Merging Columns', unit='entries'):\n",
        "        text = ''\n",
        "\n",
        "        if str(df.iloc[i]['overview']) != 'nan':\n",
        "            text += str(df.iloc[i]['overview'])\n",
        "\n",
        "        if str(df.iloc[i]['tag_list']) != 'nan':\n",
        "            text += str(df.iloc[i]['tag_list'])\n",
        "\n",
        "        if str(df.iloc[i]['description']) != 'nan':\n",
        "            text += str(df.iloc[i]['description'])\n",
        "\n",
        "        if str(df.iloc[i]['short_description']) != 'nan':\n",
        "            text += str(df.iloc[i]['short_description'])\n",
        "        \n",
        "        info.append(text)\n",
        "\n",
        "    return info\n",
        "\n",
        "descriptive_df['info'] = merge_descriptives(descriptive_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(0, 3):\n",
        "#     display(descriptive_df.iloc[i]['info'])\n",
        "\n",
        "# display(descriptive_df.columns)"
      ]
    },
    {
      "source": [
        "# Finding Word Relevance In Descriptive Column"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Matching Entries: 100%|██████████| 132107/132107 [5:30:53<00:00,  6.65entries/s]CPU times: user 5h 18min 6s, sys: 9min 10s, total: 5h 27min 17s\n",
            "Wall time: 5h 30min 53s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    *** TODO: try to implement multithreading again\n",
        "    *** TODO: split overview columm into smaller workloads and at the end,\n",
        "              append the results of every section to the sub-categories list.\n",
        "              we do this because the algorithm slows down dramatically the \n",
        "              longer it runs, so if we split it into smaller parts, we decrease\n",
        "              the risk of this slow down happening. it also makes it so i can better\n",
        "              run this on my computer, because once i start it, my computer will be \n",
        "              extremely slow for 12 continuous hours. this way i can run each segment\n",
        "              at my convinience in case i need the computing power for something else.\n",
        "\n",
        "    *** Actual running time was 12h 22min 47s. It started off at 13-17 entries per second,\n",
        "    but the longer it ran, the worse the running time got. During the last few hours, it\n",
        "    slowed down to 1-2 entries per second.\n",
        "\n",
        "    *** On second run, it took 4h 54min 25s. It started off at 13-17 entries per second, but due\n",
        "    to the shorter running time, it only had a chance to slow down to 3-7 entries per second. I \n",
        "    believe the longer running time of the first test was due to not having restarted my laptop\n",
        "    in a long time.\n",
        "\n",
        "    *** Third run took 5h 30min 53s. It had about 11 thousand more entries.\n",
        "'''\n",
        "def maxcat(ccc):\n",
        "    '''\n",
        "    This method will return the category with highest value count in dictionary ccc.\n",
        "    '''\n",
        "    values = list(ccc.values())\n",
        "    keys = list(ccc.keys())\n",
        "\n",
        "    return keys[values.index(max(values))]\n",
        "\n",
        "def category_code_eval(h, scs, df):\n",
        "    '''\n",
        "    This method will evaluate the status of the category_code\n",
        "    column in a given entry (index h) and will assign a category_code\n",
        "    if the current one is null. If it's not null, nothing will be done.\n",
        "    '''\n",
        "    if str(df.iloc[h]['category_code']) == 'nan':\n",
        "        category_code_count = {}\n",
        "\n",
        "        for sc in scs:  # here we iterate through all the sub-categories\n",
        "                        # in our final sc list from relevance_matching and\n",
        "                        # we calculate a value count for every category code\n",
        "                        # derived from the given sub-category\n",
        "            cat = cat_subcat(sc)[0]\n",
        "            if cat != None:\n",
        "                if cat in category_code_count.keys():\n",
        "                    category_code_count[cat] += 1\n",
        "                else:\n",
        "                    category_code_count[cat] = 1\n",
        "\n",
        "        # display(category_code_count)\n",
        "        if len(category_code_count) > 0: # here we pick the category with the\n",
        "                                         # highest value count and assign it to\n",
        "                                         # the entry\n",
        "            df['category_code'][h] = maxcat(category_code_count)\n",
        "\n",
        "def relevance_matching(overview, subcategories_found):\n",
        "    '''\n",
        "    This method operates on a list of descriptions and appends to a list\n",
        "    all the sub-categories that were matched for every entry in our list\n",
        "    of descriptions.\n",
        "    '''\n",
        "    h = 0   # keeps track of the index of current entry\n",
        "\n",
        "    for i in tqdm(overview, desc='Matching Entries',unit='entries'):\n",
        "        # print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n'); print(i, '\\n')\n",
        "        ov_words = i.split()    # separates the current description into a list of its words\n",
        "        prev_wordset = []   # this will be used to keep a history of the words previously searched\n",
        "        match = False\n",
        "        word_count = Value_Count()  # Value_Count will keep a dictionary of the sub-categories matched\n",
        "                                    # and how many times they were matched\n",
        "\n",
        "        for j, v in enumerate(ov_words): # here we begin operating on every word\n",
        "            if v in prev_wordset and match: # if current word was in the previous word set\n",
        "                continue                    # and match was previously set to true, move on the next word\n",
        "            \n",
        "            match = word_count.check_values(v, ov_words[j:j+4]) # here we check_values, passing current\n",
        "                                                                # word and the 4 succeeding words\n",
        "            prev_wordset = ov_words[j:j+4] # here we update the previous words\n",
        "\n",
        "        word_count.final_count() # final_count will update the dictionary stored in Value_Count by\n",
        "                                 # removing all sub-categories with 0-count\n",
        "        # display(word_count.value_count)\n",
        "\n",
        "        # ============================================================================================\n",
        "        # add word_count.value_count keys to a blank list of sub-categories and then append \n",
        "        temp_sc = ''    # stores temp sc for cleaning\n",
        "\n",
        "        # here we iterate through all the keys in our Value_Count dictionary, which\n",
        "        # should now only include the sub-categories for whom a match was found\n",
        "        for key in word_count.value_count.keys():\n",
        "            temp_key = ''\n",
        "\n",
        "            if len(key.split('_')) > 1: # if sub-category has more than one word\n",
        "                for word in key.split('_'): # capitalize and replace _'s with spaces\n",
        "                    temp_key += word.capitalize()+' '\n",
        "                \n",
        "                temp_key = temp_key[:-1]\n",
        "            else:                      # else just capitalize\n",
        "                temp_key += key.capitalize()\n",
        "\n",
        "            # add separator '; ' and append sub-category to our final list\n",
        "            temp_key += '; '\n",
        "            temp_sc += temp_key\n",
        "\n",
        "        temp_sc = temp_sc[:-2] # gets rid of final '; '\n",
        "\n",
        "        # print(temp_sc + '\\n')\n",
        "        subcategories_found.append(temp_sc) # append final string with\n",
        "                                            # formatted sub-categories\n",
        "\n",
        "        # change category_code\n",
        "        category_code_eval(h, word_count.value_count.keys(), descriptive_df)\n",
        "        h += 1\n",
        "\n",
        "    return subcategories_found\n",
        "\n",
        "# ============================================================================\n",
        "# ====== RUNNING THE ALGORITHM ===============================================\n",
        "\n",
        "overview = descriptive_df['info']\n",
        "subcategories_found = []\n",
        "\n",
        "%time subcat_column = relevance_matching(overview, subcategories_found)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Technology Platform; Social Media; Entertainment News; Technology; Proprietary; Social; Online; Platform; Internet',\n",
              " 'Platform; Internet; Video',\n",
              " 'Online; Computer; Game; Media; Service',\n",
              " 'Online Social Networking; Online',\n",
              " 'Online; Hosting',\n",
              " 'Website Design; Social Media; Media; Website; Social',\n",
              " 'Infrastructure; Alternative Energy; Green; Energy; Alternative',\n",
              " '',\n",
              " 'Advertising; Service; Instant; Information; Media',\n",
              " 'Management; Web-based',\n",
              " 'Video Chat; Alternative; Video; Chat',\n",
              " '',\n",
              " 'Software; Marketing; Solutions; Service; Virtual; Video; Web',\n",
              " 'Social Network; Social Networking; Social; News; Service; Networks; Data; Network',\n",
              " 'Marketing; Social Media; Social; Network; Web; Public; Dedicated; Support; Consumer',\n",
              " 'Online; Public; Tools; Technology; Support; Community',\n",
              " '',\n",
              " 'Image',\n",
              " 'Social Media; Ad Exchange; Management; Mobile; Platform; Application; Ad; Business; Media; Social; Based; Money',\n",
              " 'Exercise; Wearable; Data; Activity; Website; Personal; Interface; Family',\n",
              " 'Clean Energy; Technology',\n",
              " '',\n",
              " 'Software; Online',\n",
              " 'Web Application Development; Web; Design; Social; Games; Platform',\n",
              " 'Technology; Business; Website; Platform; Web; Online',\n",
              " 'Design; Internet',\n",
              " 'Software; Mobile Applications; Social Networking; Communications; Mobile; Social; Applications; Technology',\n",
              " 'Social Media; Social; Online; Content; Interface; Based; Things; Networking',\n",
              " 'Software; Revenue; Agency',\n",
              " 'Startups; Startup; Platform; Money; Support; Exchange; Equity',\n",
              " 'Social Network; Website; Community; Personal; Tools; Information; Social; Learning; Service',\n",
              " 'Software; Marketing; Advertising; Solutions; Real Estate; Technology; Information; Mapping; Web-based; Web; Platform',\n",
              " 'Search; Engine',\n",
              " 'Advertising; Engineering; Mobile; Networking; Community; Dedicated; World',\n",
              " 'Medical',\n",
              " 'Application; Game',\n",
              " 'Manufacturer',\n",
              " 'Loans; Nationwide; Car; Online; Financing',\n",
              " '',\n",
              " 'Software; Based; Online; Public; Service; Internet; Mobile; Computer; Video']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "subcat_column[:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# descriptive_df = descriptive_df[:1200]\n",
        "descriptive_df['Sub-Categories'] = subcat_column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "descriptive_df.to_csv('submapped.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}